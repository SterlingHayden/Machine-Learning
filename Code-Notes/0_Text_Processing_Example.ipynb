{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yUjf6REaUPr"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syPVWfrxaUPu",
        "outputId": "fab3d07a-bccc-4427-e8c3-dcb8f8cab6f4"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "sTp3SkN1ojjG",
        "outputId": "80edc0d3-d9e4-40fd-9394-0472439d2213"
      },
      "outputs": [],
      "source": [
        "sample_text = ['I love machine learning',\n",
        "               'It is an interesting subject',\n",
        "               'Machine Learning is a boring subject'\n",
        "               ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RRoyGBzQaUP1"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20\n",
        "embedding_dim = 5\n",
        "max_length = 5\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dXGoRbPOaUP1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'machine': 2,\n",
              " 'learning': 3,\n",
              " 'is': 4,\n",
              " 'subject': 5,\n",
              " 'i': 6,\n",
              " 'love': 7,\n",
              " 'it': 8,\n",
              " 'an': 9,\n",
              " 'interesting': 10,\n",
              " 'a': 11,\n",
              " 'boring': 12}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize, Convert to Sequence, and Pad\n",
        "\n",
        "# Create and instance of a Tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "# creates a dictionary of word and values using train data. \n",
        "# i.e for each words in train review map it to some number\n",
        "\n",
        "tokenizer.fit_on_texts(sample_text)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[6, 7, 2, 3], [8, 4, 9, 10, 5], [2, 3, 4, 11, 12, 5]]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# For sample_text\n",
        "# using tokens above convert each review into a sequence.\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_text)\n",
        "sample_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 6,  7,  2,  3,  0],\n",
              "       [ 8,  4,  9, 10,  5],\n",
              "       [ 2,  3,  4, 11, 12]], dtype=int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pad/truncate sequence to make each review of length max_length\n",
        "sample_padded = pad_sequences(sample_sequences, maxlen=5, padding='post', truncating=trunc_type)\n",
        "sample_padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The embedded text data shape is (3, 5, 10)\n",
            "An example of embedding: First embedded text sequence data is:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
              "array([[-0.03834301,  0.00479092, -0.01012387,  0.03657177, -0.01715965,\n",
              "        -0.02272273, -0.02656649,  0.0487006 , -0.0238972 ,  0.04372754],\n",
              "       [ 0.0383485 ,  0.02869339, -0.02715058,  0.009262  ,  0.02195105,\n",
              "        -0.02190059, -0.02965981,  0.00258789, -0.04203169,  0.00319447],\n",
              "       [ 0.03820566, -0.0099265 ,  0.03273856,  0.00055615,  0.01259836,\n",
              "         0.02301652, -0.01502926, -0.00572432,  0.00874148, -0.0195071 ],\n",
              "       [ 0.01847352,  0.02642194,  0.02731682, -0.04977697, -0.0393496 ,\n",
              "        -0.0372509 , -0.04752994, -0.00558472, -0.0310897 ,  0.01497186],\n",
              "       [ 0.03563477, -0.00690212,  0.04435058,  0.01988745, -0.04891148,\n",
              "         0.0187173 ,  0.04279529, -0.03194039,  0.03858398, -0.04339191]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "# Create an embedding layer\n",
        "embedding_layer = Embedding(1000, 10)\n",
        "\n",
        "# Pass some text to the embedding layer\n",
        "embedded_text = embedding_layer(sample_padded)\n",
        "# Print the shape of the output\n",
        "print('The embedded text data shape is',embedded_text.shape)\n",
        "print('An example of embedding: First embedded text sequence data is:')\n",
        "embedded_text[1,:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[6, 7, 2, 3, 1]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#What happens if we encounter words that are not in our vocabulary?\n",
        "# Note in the output, word \"application which is not in our vocabulary is represented vy 1 which is a token for <OOV>\"\n",
        "new_text = ['I love Machine Learning applications']\n",
        "new_text_sequence = tokenizer.texts_to_sequences(new_text)\n",
        "new_text_sequence"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
